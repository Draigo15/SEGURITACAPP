# ğŸ¤– ConfiguraciÃ³n de Ollama para Chatbot Inteligente

## Â¿QuÃ© es Ollama?

Ollama es una herramienta que permite ejecutar modelos de IA de forma local en tu computadora, sin necesidad de conexiÃ³n a internet ni costos adicionales. Nuestro chatbot puede usar Ollama para proporcionar respuestas mÃ¡s inteligentes y contextuales.

## ğŸ“‹ Requisitos del Sistema

### Windows
- Windows 10/11 (64-bit)
- MÃ­nimo 8GB RAM (recomendado 16GB)
- 4GB de espacio libre en disco
- Procesador moderno (Intel i5/AMD Ryzen 5 o superior)

### macOS
- macOS 11.0 o superior
- MÃ­nimo 8GB RAM (recomendado 16GB)
- 4GB de espacio libre en disco
- Chip Apple Silicon (M1/M2) o Intel

### Linux
- Ubuntu 18.04+, CentOS 7+, o distribuciÃ³n compatible
- MÃ­nimo 8GB RAM (recomendado 16GB)
- 4GB de espacio libre en disco

## ğŸš€ InstalaciÃ³n Paso a Paso

### 1. Descargar e Instalar Ollama

#### Windows
```powershell
# OpciÃ³n 1: Descargar desde el sitio web
# Ve a https://ollama.ai/download y descarga el instalador para Windows

# OpciÃ³n 2: Usar winget (si tienes Windows Package Manager)
winget install Ollama.Ollama
```

#### macOS
```bash
# OpciÃ³n 1: Descargar desde el sitio web
# Ve a https://ollama.ai/download y descarga el instalador para macOS

# OpciÃ³n 2: Usar Homebrew
brew install ollama
```

#### Linux
```bash
# Instalar usando el script oficial
curl -fsSL https://ollama.ai/install.sh | sh

# O descargar manualmente desde https://ollama.ai/download
```

### 2. Verificar la InstalaciÃ³n

Abre una terminal/PowerShell y ejecuta:

```bash
ollama --version
```

DeberÃ­as ver algo como: `ollama version 0.1.x`

### 3. Descargar el Modelo Recomendado

Para nuestro chatbot de seguridad ciudadana, recomendamos usar **Llama 3.1 8B**:

```bash
# Descargar el modelo (esto puede tomar varios minutos)
ollama pull llama3.1:8b

# Verificar que se descargÃ³ correctamente
ollama list
```

### 4. Probar el Modelo

```bash
# Iniciar una conversaciÃ³n de prueba
ollama run llama3.1:8b

# Escribe un mensaje de prueba:
# "Hola, Â¿puedes ayudarme con temas de seguridad ciudadana?"

# Para salir, escribe: /bye
```

## âš™ï¸ ConfiguraciÃ³n para la App

### 1. Iniciar el Servidor Ollama

Ollama debe estar ejecutÃ¡ndose como servicio en segundo plano:

```bash
# En Windows/macOS/Linux
ollama serve
```

**Nota:** En la mayorÃ­a de instalaciones, Ollama se inicia automÃ¡ticamente como servicio del sistema.

### 2. Verificar que el Servidor Funciona

Abre tu navegador y ve a: `http://localhost:11434`

DeberÃ­as ver: `Ollama is running`

### 3. Configurar la App

En el archivo `chatbotService.ts`, la configuraciÃ³n por defecto ya estÃ¡ lista:

```typescript
const config = {
  useLocalModel: true,        // Activar modelo local
  ollamaUrl: 'http://localhost:11434',  // URL del servidor
  modelName: 'llama3.1:8b',   // Modelo a usar
  maxTokens: 150,             // MÃ¡ximo de tokens por respuesta
  temperature: 0.7,           // Creatividad (0.0-1.0)
  fallbackToPreset: true,     // Usar respuestas predefinidas si falla
  rateLimitPerHour: 100       // LÃ­mite de consultas por hora
};
```

## ğŸ”§ Modelos Alternativos

Si tu computadora tiene limitaciones de memoria, puedes usar modelos mÃ¡s pequeÃ±os:

### Modelos Ligeros (4GB RAM)
```bash
# Modelo muy pequeÃ±o y rÃ¡pido
ollama pull llama3.1:3b

# Modelo especializado en conversaciÃ³n
ollama pull phi3:mini
```

### Modelos Potentes (16GB+ RAM)
```bash
# Modelo mÃ¡s grande y capaz
ollama pull llama3.1:13b

# Modelo especializado en instrucciones
ollama pull codellama:13b
```

## ğŸš¨ SoluciÃ³n de Problemas

### Problema: "Ollama no encontrado"
**SoluciÃ³n:**
1. Reinicia tu terminal/PowerShell
2. Verifica que Ollama estÃ© en tu PATH
3. Reinstala Ollama si es necesario

### Problema: "Modelo no encontrado"
**SoluciÃ³n:**
```bash
# Listar modelos instalados
ollama list

# Descargar el modelo si no estÃ¡
ollama pull llama3.1:8b
```

### Problema: "Servidor no responde"
**SoluciÃ³n:**
```bash
# Detener Ollama
ollama stop

# Reiniciar el servidor
ollama serve
```

### Problema: "Respuestas muy lentas"
**SoluciÃ³n:**
1. Usa un modelo mÃ¡s pequeÃ±o (3b en lugar de 8b)
2. Reduce `maxTokens` en la configuraciÃ³n
3. Cierra otras aplicaciones que consuman RAM

### Problema: "Error de memoria"
**SoluciÃ³n:**
1. Cambia a un modelo mÃ¡s pequeÃ±o
2. Reinicia tu computadora
3. Verifica que tienes suficiente RAM libre

## ğŸ“Š Monitoreo y EstadÃ­sticas

### Ver Uso de Recursos
```bash
# Ver modelos cargados en memoria
ollama ps

# Ver informaciÃ³n del sistema
ollama show llama3.1:8b
```

### Logs del Sistema
```bash
# En Linux/macOS
journalctl -u ollama

# En Windows
# Revisar Event Viewer > Applications and Services Logs
```

## ğŸ”’ Consideraciones de Seguridad

1. **Privacidad Total**: Todos los datos se procesan localmente
2. **Sin ConexiÃ³n Externa**: No se envÃ­a informaciÃ³n a servidores externos
3. **Control Completo**: TÃº controlas quÃ© modelo usar y cÃ³mo configurarlo
4. **Datos Sensibles**: Ideal para informaciÃ³n de seguridad ciudadana

## ğŸ¯ OptimizaciÃ³n de Rendimiento

### Para Computadoras Potentes
```typescript
// En chatbotService.ts
const config = {
  modelName: 'llama3.1:13b',  // Modelo mÃ¡s grande
  maxTokens: 200,             // Respuestas mÃ¡s largas
  temperature: 0.8,           // MÃ¡s creatividad
};
```

### Para Computadoras BÃ¡sicas
```typescript
// En chatbotService.ts
const config = {
  modelName: 'llama3.1:3b',   // Modelo mÃ¡s pequeÃ±o
  maxTokens: 100,             // Respuestas mÃ¡s cortas
  temperature: 0.5,           // Menos creatividad, mÃ¡s eficiencia
};
```

## ğŸ“± IntegraciÃ³n con la App

Una vez configurado Ollama:

1. **Inicia la app** de seguridad ciudadana
2. **Ve al chat** de cualquier reporte
3. **Escribe un mensaje** como ciudadano
4. **Observa** cÃ³mo el chatbot responde usando IA local
5. **Verifica** los indicadores visuales (Ã­cono de IA, nivel de urgencia)

## ğŸ†˜ Soporte

Si tienes problemas:

1. **Revisa los logs** de Ollama
2. **Consulta la documentaciÃ³n oficial**: https://ollama.ai/docs
3. **Verifica los requisitos** del sistema
4. **Prueba con un modelo mÃ¡s pequeÃ±o**

## ğŸ‰ Â¡Listo!

Ahora tienes un chatbot inteligente y privado funcionando completamente gratis en tu computadora. El chatbot puede:

- âœ… Responder preguntas sobre seguridad ciudadana
- âœ… Clasificar la urgencia de los mensajes
- âœ… Proporcionar informaciÃ³n contextual
- âœ… Funcionar sin conexiÃ³n a internet
- âœ… Mantener la privacidad de los datos
- âœ… Aprender de las conversaciones localmente

Â¡Disfruta de tu asistente virtual de seguridad ciudadana!