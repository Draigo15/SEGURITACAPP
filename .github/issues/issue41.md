## ğŸ“ DescripciÃ³n
Integrar Ollama o un LLM local para proporcionar respuestas inteligentes y conversacionales cuando la base de conocimiento no es suficiente.

## âœ… Criterios de AceptaciÃ³n
- [ ] Ollama configurado localmente o en servidor
- [ ] IntegraciÃ³n con API de Ollama
- [ ] Respuestas contextuales inteligentes
- [ ] Mantener contexto de conversaciÃ³n
- [ ] Tiempo de respuesta < 3 segundos
- [ ] Fallback a respuestas predefinidas
- [ ] Filtrado de contenido inapropiado
- [ ] DocumentaciÃ³n de configuraciÃ³n

## ğŸ”§ Tareas TÃ©cnicas
- [ ] Configurar Ollama local/servidor
- [ ] Crear servicio chatbotService.ts
- [ ] Implementar llamadas a API de Ollama
- [ ] Mantener historial de conversaciÃ³n
- [ ] Implementar streaming de respuestas
- [ ] Timeout y manejo de errores
- [ ] Filtros de contenido
- [ ] Documentar en CHATBOT_INTELIGENTE.md
- [ ] Tests de integraciÃ³n

## ğŸ“ Recursos
- [Ollama](https://ollama.ai/)
- OLLAMA_SETUP.md
- chatbotService.ts

## â±ï¸ EstimaciÃ³n
10 Story Points / 8 horas

## ğŸ‘¤ Asignado
@Draigo15
